{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (3.0.0)\n",
      "Requirement already satisfied: filelock in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from datasets) (2.1.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from datasets) (3.10.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.22.0 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from datasets) (0.25.1)\n",
      "Requirement already satisfied: packaging in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from aiohttp->datasets) (1.11.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: peft in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (0.12.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from peft) (2.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from peft) (24.1)\n",
      "Requirement already satisfied: psutil in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from peft) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from peft) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from peft) (2.4.1)\n",
      "Requirement already satisfied: transformers in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from peft) (4.44.2)\n",
      "Requirement already satisfied: tqdm in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from peft) (4.66.5)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from peft) (0.34.2)\n",
      "Requirement already satisfied: safetensors in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from peft) (0.4.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from peft) (0.25.1)\n",
      "Requirement already satisfied: filelock in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from huggingface-hub>=0.17.0->peft) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from huggingface-hub>=0.17.0->peft) (2024.6.1)\n",
      "Requirement already satisfied: requests in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch>=1.13.0->peft) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch>=1.13.0->peft) (75.1.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch>=1.13.0->peft) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch>=1.13.0->peft) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch>=1.13.0->peft) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch>=1.13.0->peft) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch>=1.13.0->peft) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch>=1.13.0->peft) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.6.68)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from transformers->peft) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from transformers->peft) (0.19.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: trl in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (0.11.0)\n",
      "Requirement already satisfied: torch>=1.4.0 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from trl) (2.4.1)\n",
      "Requirement already satisfied: transformers>=4.40.0 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from trl) (4.44.2)\n",
      "Requirement already satisfied: accelerate in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from trl) (0.34.2)\n",
      "Requirement already satisfied: datasets in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from trl) (3.0.0)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from trl) (0.8.11)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from trl) (2.1.1)\n",
      "Requirement already satisfied: filelock in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch>=1.4.0->trl) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch>=1.4.0->trl) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch>=1.4.0->trl) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch>=1.4.0->trl) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch>=1.4.0->trl) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch>=1.4.0->trl) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch>=1.4.0->trl) (75.1.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch>=1.4.0->trl) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch>=1.4.0->trl) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch>=1.4.0->trl) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch>=1.4.0->trl) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch>=1.4.0->trl) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch>=1.4.0->trl) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch>=1.4.0->trl) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch>=1.4.0->trl) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4.0->trl) (12.6.68)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from transformers>=4.40.0->trl) (0.25.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from transformers>=4.40.0->trl) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from transformers>=4.40.0->trl) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from transformers>=4.40.0->trl) (2024.9.11)\n",
      "Requirement already satisfied: requests in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from transformers>=4.40.0->trl) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from transformers>=4.40.0->trl) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from transformers>=4.40.0->trl) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from transformers>=4.40.0->trl) (4.66.5)\n",
      "Requirement already satisfied: docstring-parser>=0.16 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from tyro>=0.5.11->trl) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from tyro>=0.5.11->trl) (13.8.1)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from tyro>=0.5.11->trl) (1.7.1)\n",
      "Requirement already satisfied: psutil in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from accelerate->trl) (5.9.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from datasets->trl) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from datasets->trl) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from datasets->trl) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from datasets->trl) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from datasets->trl) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from datasets->trl) (3.10.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from aiohttp->datasets->trl) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from aiohttp->datasets->trl) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from aiohttp->datasets->trl) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from aiohttp->datasets->trl) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from aiohttp->datasets->trl) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from aiohttp->datasets->trl) (1.11.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from requests->transformers>=4.40.0->trl) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from requests->transformers>=4.40.0->trl) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from requests->transformers>=4.40.0->trl) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from requests->transformers>=4.40.0->trl) (2024.8.30)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.15.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from jinja2->torch>=1.4.0->trl) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from pandas->datasets->trl) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from pandas->datasets->trl) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from pandas->datasets->trl) (2024.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: bitsandbytes in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (0.43.3)\n",
      "Requirement already satisfied: torch in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from bitsandbytes) (2.4.1)\n",
      "Requirement already satisfied: numpy in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from bitsandbytes) (2.1.1)\n",
      "Requirement already satisfied: filelock in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch->bitsandbytes) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch->bitsandbytes) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch->bitsandbytes) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch->bitsandbytes) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch->bitsandbytes) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch->bitsandbytes) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch->bitsandbytes) (75.1.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch->bitsandbytes) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch->bitsandbytes) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch->bitsandbytes) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch->bitsandbytes) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch->bitsandbytes) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch->bitsandbytes) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch->bitsandbytes) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from torch->bitsandbytes) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.6.68)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ipywidgets in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (8.1.5)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from ipywidgets) (8.27.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: decorator in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: executing in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six in /home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages (from asttokens->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets\n",
    "%pip install peft\n",
    "%pip install trl\n",
    "%pip install bitsandbytes\n",
    "%pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from trl import DataCollatorForCompletionOnlyLM, SFTConfig, SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"HuggingFaceTB/SmolLM-135M-Instruct\"\n",
    "dataset_id = \"medalpaca/medical_meadow_medical_flashcards\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing and Formatting the Dataset for Training\n",
    "\n",
    "We'll be preparing a dataset for training a Language Model (LLM). The steps involve formatting the dataset to keep only the necessary columns and splitting it into training and evaluation sets. Proper dataset preparation is crucial for ensuring the model's effectiveness and generalization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dataset(dataset, keys, instruction_col_name, response_col_name):\n",
    "    \"\"\"Format the dataset by retaining only necessary columns and renaming them.\"\"\"\n",
    "    cols_to_remove = [key for key in keys if key not in [instruction_col_name, response_col_name]]\n",
    "    dataset = dataset.remove_columns(cols_to_remove)\n",
    "    dataset = dataset.rename_column(instruction_col_name, \"instruction\")\n",
    "    dataset = dataset.rename_column(response_col_name, \"response\")\n",
    "    return dataset\n",
    "\n",
    "def prepare_datasets(dataset, instruction_col_name, response_col_name):\n",
    "    \"\"\"Format and split the dataset for training and evaluation.\"\"\"\n",
    "    available_cols = list(dataset[\"train\"].features.keys())\n",
    "    formatted_dataset = format_dataset(\n",
    "        dataset, available_cols, instruction_col_name, response_col_name\n",
    "    )\n",
    "\n",
    "    if \"valid\" in formatted_dataset:\n",
    "        train_dataset = formatted_dataset[\"train\"]\n",
    "        eval_dataset = formatted_dataset[\"valid\"]\n",
    "    elif \"test\" in formatted_dataset:\n",
    "        train_dataset = formatted_dataset[\"train\"]\n",
    "        eval_dataset = formatted_dataset[\"test\"]\n",
    "    else:\n",
    "        split_dataset = formatted_dataset[\"train\"].train_test_split(test_size=0.2)\n",
    "        train_dataset, eval_dataset = split_dataset[\"train\"], split_dataset[\"test\"]\n",
    "\n",
    "    return train_dataset, eval_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset using its ID or path. This dataset will be used for training and evaluating the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06e110a88ceb4575918ae532493ec9f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "157aeb01dada4aacad57804ac3ea5987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)l_meadow_wikidoc_medical_flashcards.json:   0%|          | 0.00/17.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b57b529ca40b4bf5a49e561f68a31aac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/33955 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the dataset information to inspect its structure and column names. This is important to understand the data we're working with and ensure that we correctly identify the columns containing the `instructions` and `responses`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input', 'output', 'instruction'],\n",
       "        num_rows: 33955\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the relationship between very low Mg2+ levels, PTH levels, and Ca2+ levels?',\n",
       " 'output': 'Very low Mg2+ levels correspond to low PTH levels which in turn results in low Ca2+ levels.',\n",
       " 'instruction': 'Answer this question truthfully'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format the dataset and split it into training and evaluation sets. Here, `input` and `output` represent the columns in the dataset holding the `instruction` and `response`, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, eval_dataset = prepare_datasets(\n",
    "    dataset, instruction_col_name=\"input\", response_col_name=\"output\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset = Dataset({\n",
      "    features: ['instruction', 'response'],\n",
      "    num_rows: 27164\n",
      "})\n",
      "eval_dataset = Dataset({\n",
      "    features: ['instruction', 'response'],\n",
      "    num_rows: 6791\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(f\"{train_dataset = }\")\n",
    "print(f\"{eval_dataset = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Test Pre-trained Model\n",
    "\n",
    "Define Functions for Response Generation and Display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(model, tokenizer, instruction, device=\"cpu\"):\n",
    "    \"\"\"Generate a response from the model based on an instruction.\"\"\"\n",
    "    messages = [{\"role\": \"user\", \"content\": instruction}]\n",
    "    input_text = tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(\n",
    "        inputs, max_new_tokens=128, temperature=0.2, top_p=0.9, do_sample=True\n",
    "    )\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "def print_example(example):\n",
    "    \"\"\"Print an example from the dataset.\"\"\"\n",
    "    print(f\"Original Dataset Example:\")\n",
    "    print(f\"Instruction: {example['instruction']}\")\n",
    "    print(f\"Response: {example['response']}\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "def print_response(response):\n",
    "    \"\"\"Print the model's response.\"\"\"\n",
    "    print(f\"Model response:\")\n",
    "    print(response.split(\"assistant\\n\")[-1])\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Model, and the Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17dc7bd6adcf4985abb253f26cb0ba4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.59k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbeca3d18bff427a8c530083c8f5922a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/801k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26a8d19b5cce4829920e107fda06fbff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e76a0f895994deb99b8aaf7f9a00458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "192c61efc6b74280bf6cff9cbded2506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/565 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1ef7433a0df41d497f623b661e937ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/723 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f096defa9844b938c60986f5e39520c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/269M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53f12cdf2cd64e5487d82b55d9428728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the Pre-trained Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset Example:\n",
      "Instruction: What thyroid imbalance is associated with anxiety?\n",
      "Response: Hyperthyroidism presents with anxiety.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model response:\n",
      "Thyroid imbalance is a common condition that can contribute to anxiety. Thyroid dysfunction, which affects the thyroid gland, can lead to anxiety symptoms. Here are some ways thyroid imbalance can contribute to anxiety:\n",
      "\n",
      "1. **Hypothyroidism**: Hypothyroidism, or underactive thyroid, can cause anxiety by disrupting the body's natural balance of hormones. This can lead to feelings of fatigue, weight gain, and mood disturbances.\n",
      "2. **Hyperthyroidism**: Hyperthyroidism, or overactive thyroid, can cause anxiety by disrupting the body's natural balance of hormones. This can lead to feelings of anxiety, jitteriness, and rapid heartbeat.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define a test example\n",
    "example1 = eval_dataset[1]\n",
    "\n",
    "response = generate_response(model, tokenizer, example1[\"instruction\"], device)\n",
    "\n",
    "print_example(example1)\n",
    "print_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Fine-tuning Trainer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training adapters [Read More](https://huggingface.co/docs/trl/v0.9.6/en/sft_trainer#training-adapters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huggingface support tight integration with PEFT library so that we can conveniently train adapters instead of training the entire model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Customize prompts using packed dataset [Read More](https://huggingface.co/docs/trl/en/sft_trainer#customize-your-prompts-using-packed-dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our dataset has two field `instruction` and `response`, we need to combine them as one string to be able to past it to the SFT Trainer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_prompts_func(example: dict) -> str:\n",
    "    \"\"\"Format prompt for training.\"\"\"\n",
    "    text = f\"<|im_start|>user\\n{example['instruction']}<|im_end|>\\n<|im_start|>assistant\\n{example['response']}<|im_end|>\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "122a41d0d7314581bdb19195326b730b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff2a90fbe3b2444c9e545208afab5324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_train_epochs = 100\n",
    "\n",
    "output_dir = f\"{model_id.split('/')[-1]}-{dataset_id.split('/')[-1]}-{num_train_epochs}epochs\"\n",
    "\n",
    "sft_config = SFTConfig(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    max_seq_length=512,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    gradient_checkpointing=True,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=500,  # save checkpoints every n training steps\n",
    "    logging_steps=500,\n",
    "    learning_rate=1e-3,\n",
    "    weight_decay=0.001,\n",
    "    fp16=False,\n",
    "    bf16=True,\n",
    "    warmup_ratio=0.05,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    packing=True\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    formatting_func=formatting_prompts_func,\n",
    "    peft_config=peft_config,\n",
    "    args=sft_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 2            |        cudaMalloc retries: 2         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |   1112 MiB |   4883 MiB |  41364 MiB |  40251 MiB |\n",
      "|       from large pool |   1079 MiB |   4851 MiB |  38604 MiB |  37525 MiB |\n",
      "|       from small pool |     32 MiB |     34 MiB |   2759 MiB |   2726 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |   1112 MiB |   4883 MiB |  41364 MiB |  40251 MiB |\n",
      "|       from large pool |   1079 MiB |   4851 MiB |  38604 MiB |  37525 MiB |\n",
      "|       from small pool |     32 MiB |     34 MiB |   2759 MiB |   2726 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |   1104 MiB |   4874 MiB |  41290 MiB |  40185 MiB |\n",
      "|       from large pool |   1071 MiB |   4842 MiB |  38569 MiB |  37497 MiB |\n",
      "|       from small pool |     32 MiB |     34 MiB |   2720 MiB |   2687 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |   5208 MiB |   5280 MiB |   6168 MiB |    960 MiB |\n",
      "|       from large pool |   5174 MiB |   5246 MiB |   6124 MiB |    950 MiB |\n",
      "|       from small pool |     34 MiB |     38 MiB |     44 MiB |     10 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory | 171491 KiB | 363239 KiB |  19929 MiB |  19761 MiB |\n",
      "|       from large pool | 170448 KiB | 360912 KiB |  16863 MiB |  16697 MiB |\n",
      "|       from small pool |   1043 KiB |   9153 KiB |   3065 MiB |   3064 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     584    |     633    |  160866    |  160282    |\n",
      "|       from large pool |     184    |     225    |    3288    |    3104    |\n",
      "|       from small pool |     400    |     411    |  157578    |  157178    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     584    |     633    |  160866    |  160282    |\n",
      "|       from large pool |     184    |     225    |    3288    |    3104    |\n",
      "|       from small pool |     400    |     411    |  157578    |  157178    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |     107    |     110    |     121    |      14    |\n",
      "|       from large pool |      90    |      93    |      99    |       9    |\n",
      "|       from small pool |      17    |      19    |      22    |       5    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      51    |     108    |   78001    |   77950    |\n",
      "|       from large pool |      29    |      58    |    2022    |    1993    |\n",
      "|       from small pool |      22    |      53    |   75979    |   75957    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "963e177300aa41e6915252bebac3f9ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1645 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4248, 'grad_norm': 0.11244793981313705, 'learning_rate': 0.001, 'epoch': 1.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3429, 'grad_norm': 0.14638756215572357, 'learning_rate': 0.001, 'epoch': 3.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2936, 'grad_norm': 0.14381001889705658, 'learning_rate': 0.001, 'epoch': 4.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/tfmhitesh/.conda/envs/MedAI-SmolLM135M/lib/python3.12/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1721.3863, 'train_samples_per_second': 15.281, 'train_steps_per_second': 0.956, 'train_loss': 1.3473510649428904, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1645, training_loss=1.3473510649428904, metrics={'train_runtime': 1721.3863, 'train_samples_per_second': 15.281, 'train_steps_per_second': 0.956, 'total_flos': 8656664365301760.0, 'train_loss': 1.3473510649428904, 'epoch': 5.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "302885fef83a41c3836697dc4cedfcf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_runtime': 25.3956,\n",
       " 'eval_samples_per_second': 52.253,\n",
       " 'eval_steps_per_second': 6.537,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Fine-tuned Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset Example:\n",
      "Instruction: What thyroid imbalance is associated with anxiety?\n",
      "Response: Hyperthyroidism presents with anxiety.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model response:\n",
      "Hypothyroidism is the thyroid imbalance that is associated with anxiety.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ft_model = AutoModelForCausalLM.from_pretrained(output_dir).to(device)\n",
    "\n",
    "response = generate_response(ft_model, tokenizer, example1[\"instruction\"], device)\n",
    "\n",
    "print_example(example1)\n",
    "print_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Many Responses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================= 1 ==========================\n",
      "Original Dataset Example:\n",
      "Instruction: What type of toxin is produced by Shigella dysenteriae?\n",
      "Response: Shigella dysenteriae produces Shiga toxin. Shigella is a type of bacteria that can cause an infection called shigellosis. There are several species of Shigella, and each one may produce different types of toxins. Shigella dysenteriae is one species that is known to produce a toxin called Shiga toxin. This toxin can cause damage to the lining of the intestine and lead to symptoms such as bloody diarrhea, abdominal pain, and fever. In severe cases, Shiga toxin can also cause a condition called hemolytic uremic syndrome (HUS), which can lead to kidney failure and other complications. Treatment for shigellosis typically involves rest, fluids, and antibiotics if necessary. If a person with shigellosis develops severe symptoms or complications such as HUS, they may require hospitalization and more intensive treatment.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model response:\n",
      "Shigella dysenteriae produces a toxin called shiga-like protein.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "======================= 2 ==========================\n",
      "Original Dataset Example:\n",
      "Instruction: What is the effect of increases in hemoglobin F on the O2-hemoglobin dissociation curve?\n",
      "Response: Increases in hemoglobin F cause the O2-hemoglobin dissociation curve to shift to the left. This means that at any given partial pressure of oxygen, hemoglobin will bind more tightly to oxygen, making it less available for use by the body. Hemoglobin F is a type of hemoglobin that is found in fetal blood and has a higher affinity for oxygen than adult hemoglobin. This allows the fetus to extract oxygen from the mother's blood more efficiently. In adults, increased levels of hemoglobin F can occur in certain genetic disorders, such as sickle cell anemia and thalassemia. Understanding the effects of hemoglobin F on the O2-hemoglobin dissociation curve is important for the diagnosis and management of these disorders.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model response:\n",
      "Increases in hemoglobin F cause an increase in the O2-hemoglobin dissociation curve.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "======================= 3 ==========================\n",
      "Original Dataset Example:\n",
      "Instruction: What is the highly vascularized layer of the subventricular zone that bleeding usually originates from in neonatal intraventricular hemorrhage, and at what gestational age does it start disappearing?\n",
      "Response: In neonatal intraventricular hemorrhage, bleeding usually originates from the germinal matrix, which is a highly vascularized layer of the subventricular zone that starts disappearing at 28 weeks gestation.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model response:\n",
      "The highly vascularized layer of the subventricular zone that bleeding usually originates from in neonatal intraventricular hemorrhage, and at what gestational age does it start disappearing? The layer is called the choroid plexus, which is the most vascularized layer of the subventricular zone. In neonatal intraventricular hemorrhage, bleeding from the choroid plexus can occur as a result of the blood flowing from the placenta to the brain. The choroid plexus is responsible for filtering and nourishing the blood vessels in the brain, and bleeding from this layer can be a serious complication. If bleeding occurs in the choroid plexus, it can\n",
      "----------------------------------------------------------------------------------------------------\n",
      "======================= 4 ==========================\n",
      "Original Dataset Example:\n",
      "Instruction: What is the role of the WT1 gene in the regulation of development?\n",
      "Response: The WT1 gene is a tumor suppressor gene that encodes a transcription factor which regulates urogenital development.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model response:\n",
      "The WT1 gene is a transcription factor that plays a crucial role in the development of the nervous system. Specifically, it regulates the expression of genes involved in the development of the nervous system, including those involved in the development of the spinal cord and the peripheral nervous system. Specifically, WT1 is involved in the development of the peripheral nervous system, which includes the peripheral nervous system that includes the peripheral nervous system and the peripheral nervous system that includes the peripheral nervous system and the peripheral nervous system. WT1 is also involved in the development of the central nervous system, which includes the central nervous system that includes the brain and spinal cord\n",
      "----------------------------------------------------------------------------------------------------\n",
      "======================= 5 ==========================\n",
      "Original Dataset Example:\n",
      "Instruction: What does a survival cohort describe and how does it introduce bias into the results of a retrospective case series?\n",
      "Response: A survival cohort describes the past history of prevalent cases, and this introduces bias into the results of a retrospective case series. A survival cohort is a group of individuals who have a certain characteristic or disease and are followed over time to assess outcomes. In a retrospective case series, data is collected from medical records or other sources after the fact, and a survival cohort may be used to identify cases. However, because a survival cohort only includes individuals who have survived up to a certain point, it may not accurately represent the true population of cases. This can lead to bias in the results of the case series.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model response:\n",
      "A survival cohort describes a cohort of patients who have survived a specific event or disease. This cohort is a group of patients who have been studied over time and have been followed up with the same outcome. In contrast, a retrospective case series describes a cohort of patients who have been studied and have been followed up with the same outcome. This cohort is more susceptible to bias because it is based on the same data and may not be representative of the population of patients who have been studied. Therefore, it is important to carefully evaluate the data and ensure that it is representative of the population of patients who have been studied.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "======================= 6 ==========================\n",
      "Original Dataset Example:\n",
      "Instruction: Is there a gender difference in the prevalence of tension headaches, and if so, which gender is more commonly affected?\n",
      "Response: Tension headaches are known to be more common in females than in males, although the reason for this gender difference is not entirely clear.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model response:\n",
      "Yes, there is a gender difference in the prevalence of tension headaches. Tension headaches are a type of headache that is characterized by pain or tenderness in the scalp, neck, or shoulder muscles. They are more common in women than in men, and are more commonly associated with pregnancy and childbirth. However, tension headaches can also occur in people of any age, and may be caused by a variety of factors, including stress, fatigue, and certain medications.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "======================= 7 ==========================\n",
      "Original Dataset Example:\n",
      "Instruction: For a child with suspected immune thrombocytopenia who presents with mucosal bleeding, what is the recommended next step in management?\n",
      "Response: The recommended next step in management for a child with suspected immune thrombocytopenia who presents with mucosal bleeding is to administer corticosteroids. If the child does not respond to corticosteroids, intravenous immunoglobulin (IVIG) may be considered as the next step in management. Corticosteroids have been shown to be effective in increasing platelet counts and reducing bleeding symptoms in children with immune thrombocytopenia. IVIG is another treatment option that can be used if corticosteroids are not effective or if the child cannot tolerate them. It is important for healthcare providers to monitor the child's symptoms closely and adjust their treatment plan as needed to achieve optimal outcomes while minimizing the risk of adverse effects. In addition, healthcare providers should also address any modifiable risk factors for bleeding, such as hypertension and coagulation disorders, and provide supportive care to help manage the child's symptoms and prevent complications.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model response:\n",
      "The recommended next step in management for a child with suspected immune thrombocytopenia who presents with mucosal bleeding is to perform a thrombectomy.\n",
      "\n",
      "Immune thrombocytopenia is a rare condition in which the immune system mistakenly attacks the blood cells that normally help to prevent blood clots from forming. Children with immune thrombocytopenia are at increased risk of developing bleeding, and a thrombectomy is a procedure that involves removing the spleen and blood from the spleen to prevent the formation of blood clots. In children with immune thrombocytopenia, the spleen is a common site for the formation of blood clots. A thrombectomy can help\n",
      "----------------------------------------------------------------------------------------------------\n",
      "======================= 8 ==========================\n",
      "Original Dataset Example:\n",
      "Instruction: What is the medical procedure that may be performed on patients with pelvic inflammatory disease or a ruptured ectopic pregnancy to extract and ascertain the fluid contents?\n",
      "Response: Patients with pelvic inflammatory disease or a ruptured ectopic pregnancy may have culdocentesis performed to extract and ascertain the fluid contents.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model response:\n",
      "The medical procedure that may be performed on patients with pelvic inflammatory disease or a ruptured ectopic pregnancy to extract and ascertain the fluid contents is a laparoscopy.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "======================= 9 ==========================\n",
      "Original Dataset Example:\n",
      "Instruction: What is a thyroglossal duct cyst and how does it present?\n",
      "Response: A thyroglossal duct cyst is a congenital abnormality that occurs when remnants of the thyroglossal duct, which is a structure that connects the thyroid gland to the tongue during fetal development, fail to disappear. These cysts present as anterior, midline neck masses that move with swallowing or protrusion of the tongue. They may be painless or tender and can become infected, leading to redness, warmth, and drainage. Treatment typically involves surgical removal of the cyst and any associated structures to prevent recurrence.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model response:\n",
      "A thyroglossal duct cyst is a type of cyst that arises from the thyroid gland and is characterized by a prominent, rounded, and symmetrical mass. This mass can be seen on imaging studies such as CT or MRI scans. The thyroglossal duct is a small, muscular duct that runs from the thyroid gland to the hypopharynx, and it is responsible for producing thyroid hormones. When this duct becomes blocked, it can cause a variety of symptoms, including pain, swelling, and difficulty swallowing. The thyroglossal duct cyst is typically diagnosed through a physical examination and imaging studies, and treatment may involve surgery to remove the\n",
      "----------------------------------------------------------------------------------------------------\n",
      "======================= 10 ==========================\n",
      "Original Dataset Example:\n",
      "Instruction: What is cretinism and how is it related to hypothyroidism in neonates and infants?\n",
      "Response: Cretinism is a condition that occurs in neonates and infants who have severe and prolonged hypothyroidism, which is a deficiency in thyroid hormone production. The lack of thyroid hormone can lead to stunted growth, intellectual disability, and other developmental abnormalities. Cretinism is a preventable condition that can be treated effectively with early detection and treatment of hypothyroidism. Understanding the relationship between cretinism and hypothyroidism in neonates and infants is important for its prevention and management, as it can have serious consequences for the child's physical and cognitive development.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model response:\n",
      "Cretinism is a condition characterized by the failure to produce thyroid hormone, which can lead to a range of symptoms, including hypothyroidism. In neonates and infants, cretinism is often associated with hypothyroidism, which can be caused by a variety of factors, including genetic disorders, autoimmune diseases, and certain medications. The exact cause of hypothyroidism in these populations is not fully understood, but it is thought to be related to the production of thyroid hormones by the thyroid gland. Treatment for hypothyroidism in these populations may involve thyroid hormone replacement therapy, which can help to restore normal thyroid function and improve symptoms.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "for i in range(10):\n",
    "    example = eval_dataset[random.randint(1, len(eval_dataset))]\n",
    "    test_response = generate_response(ft_model, tokenizer, example[\"instruction\"], device)\n",
    "\n",
    "    print(\"=======================\", (i+1), \"==========================\")\n",
    "    print_example(example)\n",
    "    print_response(test_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Push the fine-tuned model to your HuggingFace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "784efb2102f74fddb7ac729cf54837ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/3.70M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e745063c8beb49fdaa58d47cc745cdf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfa2b2bc46f343e5bc1b9461650f9996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/5.50k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hf_access_token = \"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\"\n",
    "if hf_access_token:\n",
    "    trainer.push_to_hub(token=hf_access_token)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MedAI-SmolLM135M",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
