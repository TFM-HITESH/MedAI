{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 79.0273556231003,
  "eval_steps": 500,
  "global_step": 26000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 1.5197568389057752,
      "grad_norm": 0.11087402701377869,
      "learning_rate": 0.001,
      "loss": 1.4246,
      "step": 500
    },
    {
      "epoch": 3.0395136778115504,
      "grad_norm": 0.14058388769626617,
      "learning_rate": 0.001,
      "loss": 1.343,
      "step": 1000
    },
    {
      "epoch": 4.5592705167173255,
      "grad_norm": 0.14454783499240875,
      "learning_rate": 0.001,
      "loss": 1.2933,
      "step": 1500
    },
    {
      "epoch": 6.079027355623101,
      "grad_norm": 0.16288474202156067,
      "learning_rate": 0.001,
      "loss": 1.2624,
      "step": 2000
    },
    {
      "epoch": 7.598784194528875,
      "grad_norm": 0.1749546080827713,
      "learning_rate": 0.001,
      "loss": 1.2298,
      "step": 2500
    },
    {
      "epoch": 9.118541033434651,
      "grad_norm": 0.1861453652381897,
      "learning_rate": 0.001,
      "loss": 1.206,
      "step": 3000
    },
    {
      "epoch": 10.638297872340425,
      "grad_norm": 0.19856591522693634,
      "learning_rate": 0.001,
      "loss": 1.1825,
      "step": 3500
    },
    {
      "epoch": 12.158054711246201,
      "grad_norm": 0.2096509486436844,
      "learning_rate": 0.001,
      "loss": 1.1685,
      "step": 4000
    },
    {
      "epoch": 13.677811550151976,
      "grad_norm": 0.23079277575016022,
      "learning_rate": 0.001,
      "loss": 1.1496,
      "step": 4500
    },
    {
      "epoch": 15.19756838905775,
      "grad_norm": 0.23993003368377686,
      "learning_rate": 0.001,
      "loss": 1.1363,
      "step": 5000
    },
    {
      "epoch": 16.717325227963524,
      "grad_norm": 0.24106284976005554,
      "learning_rate": 0.001,
      "loss": 1.1235,
      "step": 5500
    },
    {
      "epoch": 18.237082066869302,
      "grad_norm": 0.24820154905319214,
      "learning_rate": 0.001,
      "loss": 1.112,
      "step": 6000
    },
    {
      "epoch": 19.756838905775076,
      "grad_norm": 0.26187747716903687,
      "learning_rate": 0.001,
      "loss": 1.1023,
      "step": 6500
    },
    {
      "epoch": 21.27659574468085,
      "grad_norm": 0.2678745985031128,
      "learning_rate": 0.001,
      "loss": 1.0932,
      "step": 7000
    },
    {
      "epoch": 22.796352583586625,
      "grad_norm": 0.2732801139354706,
      "learning_rate": 0.001,
      "loss": 1.0865,
      "step": 7500
    },
    {
      "epoch": 24.316109422492403,
      "grad_norm": 0.27954167127609253,
      "learning_rate": 0.001,
      "loss": 1.077,
      "step": 8000
    },
    {
      "epoch": 25.835866261398177,
      "grad_norm": 0.29230767488479614,
      "learning_rate": 0.001,
      "loss": 1.0732,
      "step": 8500
    },
    {
      "epoch": 27.35562310030395,
      "grad_norm": 0.31502199172973633,
      "learning_rate": 0.001,
      "loss": 1.0632,
      "step": 9000
    },
    {
      "epoch": 28.875379939209726,
      "grad_norm": 0.314107209444046,
      "learning_rate": 0.001,
      "loss": 1.0631,
      "step": 9500
    },
    {
      "epoch": 30.3951367781155,
      "grad_norm": 0.302936851978302,
      "learning_rate": 0.001,
      "loss": 1.0537,
      "step": 10000
    },
    {
      "epoch": 31.914893617021278,
      "grad_norm": 0.29010626673698425,
      "learning_rate": 0.001,
      "loss": 1.0525,
      "step": 10500
    },
    {
      "epoch": 33.43465045592705,
      "grad_norm": 0.32046446204185486,
      "learning_rate": 0.001,
      "loss": 1.0435,
      "step": 11000
    },
    {
      "epoch": 34.954407294832826,
      "grad_norm": 0.3422679007053375,
      "learning_rate": 0.001,
      "loss": 1.0456,
      "step": 11500
    },
    {
      "epoch": 36.474164133738604,
      "grad_norm": 0.32034948468208313,
      "learning_rate": 0.001,
      "loss": 1.0359,
      "step": 12000
    },
    {
      "epoch": 37.993920972644375,
      "grad_norm": 0.32696086168289185,
      "learning_rate": 0.001,
      "loss": 1.0383,
      "step": 12500
    },
    {
      "epoch": 39.51367781155015,
      "grad_norm": 0.29580581188201904,
      "learning_rate": 0.001,
      "loss": 1.0284,
      "step": 13000
    },
    {
      "epoch": 41.03343465045592,
      "grad_norm": 0.3324735164642334,
      "learning_rate": 0.001,
      "loss": 1.0325,
      "step": 13500
    },
    {
      "epoch": 42.5531914893617,
      "grad_norm": 0.3088604807853699,
      "learning_rate": 0.001,
      "loss": 1.0228,
      "step": 14000
    },
    {
      "epoch": 44.07294832826748,
      "grad_norm": 0.3445807695388794,
      "learning_rate": 0.001,
      "loss": 1.0269,
      "step": 14500
    },
    {
      "epoch": 45.59270516717325,
      "grad_norm": 0.33308324217796326,
      "learning_rate": 0.001,
      "loss": 1.0184,
      "step": 15000
    },
    {
      "epoch": 47.11246200607903,
      "grad_norm": 0.3461936414241791,
      "learning_rate": 0.001,
      "loss": 1.0207,
      "step": 15500
    },
    {
      "epoch": 48.632218844984806,
      "grad_norm": 0.32928311824798584,
      "learning_rate": 0.001,
      "loss": 1.0151,
      "step": 16000
    },
    {
      "epoch": 50.151975683890576,
      "grad_norm": 0.3238476514816284,
      "learning_rate": 0.001,
      "loss": 1.0162,
      "step": 16500
    },
    {
      "epoch": 51.671732522796354,
      "grad_norm": 0.3503732979297638,
      "learning_rate": 0.001,
      "loss": 1.0125,
      "step": 17000
    },
    {
      "epoch": 53.191489361702125,
      "grad_norm": 0.32343536615371704,
      "learning_rate": 0.001,
      "loss": 1.0113,
      "step": 17500
    },
    {
      "epoch": 54.7112462006079,
      "grad_norm": 0.3301333785057068,
      "learning_rate": 0.001,
      "loss": 1.0088,
      "step": 18000
    },
    {
      "epoch": 56.23100303951368,
      "grad_norm": 0.3329049348831177,
      "learning_rate": 0.001,
      "loss": 1.0074,
      "step": 18500
    },
    {
      "epoch": 57.75075987841945,
      "grad_norm": 0.34890225529670715,
      "learning_rate": 0.001,
      "loss": 1.0068,
      "step": 19000
    },
    {
      "epoch": 59.27051671732523,
      "grad_norm": 0.3521020710468292,
      "learning_rate": 0.001,
      "loss": 1.0038,
      "step": 19500
    },
    {
      "epoch": 60.790273556231,
      "grad_norm": 0.35883283615112305,
      "learning_rate": 0.001,
      "loss": 1.0037,
      "step": 20000
    },
    {
      "epoch": 62.31003039513678,
      "grad_norm": 0.33201485872268677,
      "learning_rate": 0.001,
      "loss": 1.0007,
      "step": 20500
    },
    {
      "epoch": 63.829787234042556,
      "grad_norm": 0.3412777781486511,
      "learning_rate": 0.001,
      "loss": 1.0009,
      "step": 21000
    },
    {
      "epoch": 65.34954407294833,
      "grad_norm": 0.36233896017074585,
      "learning_rate": 0.001,
      "loss": 0.9974,
      "step": 21500
    },
    {
      "epoch": 66.8693009118541,
      "grad_norm": 0.3302571475505829,
      "learning_rate": 0.001,
      "loss": 1.0,
      "step": 22000
    },
    {
      "epoch": 68.38905775075987,
      "grad_norm": 0.3609643578529358,
      "learning_rate": 0.001,
      "loss": 0.9936,
      "step": 22500
    },
    {
      "epoch": 69.90881458966565,
      "grad_norm": 0.3421984910964966,
      "learning_rate": 0.001,
      "loss": 0.9981,
      "step": 23000
    },
    {
      "epoch": 71.42857142857143,
      "grad_norm": 0.36456289887428284,
      "learning_rate": 0.001,
      "loss": 0.9923,
      "step": 23500
    },
    {
      "epoch": 72.94832826747721,
      "grad_norm": 0.3589473068714142,
      "learning_rate": 0.001,
      "loss": 0.9971,
      "step": 24000
    },
    {
      "epoch": 74.46808510638297,
      "grad_norm": 0.3569645583629608,
      "learning_rate": 0.001,
      "loss": 0.9887,
      "step": 24500
    },
    {
      "epoch": 75.98784194528875,
      "grad_norm": 0.3648380935192108,
      "learning_rate": 0.001,
      "loss": 0.9944,
      "step": 25000
    },
    {
      "epoch": 77.50759878419453,
      "grad_norm": 0.3525194525718689,
      "learning_rate": 0.001,
      "loss": 0.9863,
      "step": 25500
    },
    {
      "epoch": 79.0273556231003,
      "grad_norm": 0.3629269301891327,
      "learning_rate": 0.001,
      "loss": 0.9931,
      "step": 26000
    }
  ],
  "logging_steps": 500,
  "max_steps": 32900,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 100,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.3682268566854042e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
